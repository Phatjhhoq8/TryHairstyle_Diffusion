# ðŸ”„ TryHairStyle - Luá»“ng Thá»±c Thi Chi Tiáº¿t

TÃ i liá»‡u mÃ´ táº£ chi tiáº¿t luá»“ng cháº¡y tá»« **hÃ m nÃ o trong file nÃ o**, tá»« khi truyá»n áº£nh Ä‘áº§u vÃ o Ä‘áº¿n hÃ¬nh Ä‘áº§u ra.

---

## ðŸ“Š SÆ¡ Äá»“ Tá»•ng Quan

```mermaid
flowchart TD
    A["ðŸ–¼ï¸ User Upload 2 Images"] --> B["main.py:generate_hair()"]
    B --> C["tasks.py:process_hair_transfer()"]
    C --> D["tasks.py:get_services()"]
    D --> E["face.py:FaceInfoService.__init__()"]
    D --> F["mask.py:SegmentationService.__init__()"]
    D --> G["diffusion.py:HairDiffusionService.__init__()"]
    G --> H["diffusion.py:_load_sdxl_pipeline()"]
    C --> I["face.py:FaceInfoService.analyze()"]
    C --> J["mask.py:SegmentationService.get_mask()"]
    C --> K["transformers:depth_estimator()"]
    C --> L["diffusion.py:HairDiffusionService.generate()"]
    L --> M["ðŸ“¤ result_{task_id}.png"]
```

---

## ðŸ“‹ Báº£ng Tá»•ng Há»£p Thá»© Tá»± Gá»i HÃ m

| # | HÃ m | File | DÃ²ng | Má»¥c Ä‘Ã­ch |
|:---:|:---|:---|:---:|:---|
| 1 | `generate_hair()` | `backend/app/main.py` | 48-79 | Nháº­n request, lÆ°u file, trigger Celery |
| 2 | `get_services()` | `backend/app/tasks.py` | 29-50 | Lazy load 3 AI services |
| 3 | `FaceInfoService.__init__()` | `backend/app/services/face.py` | 7-20 | Khá»Ÿi táº¡o InsightFace |
| 4 | `SegmentationService.__init__()` | `backend/app/services/mask.py` | 56-68 | Khá»Ÿi táº¡o BiSeNet |
| 5 | `HairDiffusionService.__init__()` | `backend/app/services/diffusion.py` | 20-44 | Khá»Ÿi táº¡o Diffusion |
| 6 | `_load_sdxl_pipeline()` | `backend/app/services/diffusion.py` | 112-182 | Load SDXL+ControlNet+IP-Adapter |
| 7 | `process_hair_transfer()` | `backend/app/tasks.py` | 52-134 | **Task chÃ­nh** Ä‘iá»u phá»‘i |
| 8 | `FaceInfoService.analyze()` | `backend/app/services/face.py` | 22-37 | Detect face |
| 9 | `SegmentationService.get_mask()` | `backend/app/services/mask.py` | 70-98 | Táº¡o hair mask |
| 10 | `HairDiffusionService.generate()` | `backend/app/services/diffusion.py` | 214-349 | Sinh áº£nh AI |

---

## ðŸ”µ CHI TIáº¾T Tá»ªNG HÃ€M

---

### **1. `generate_hair()` - API Endpoint**

| File | `backend/app/main.py` |
|:---|:---|
| **DÃ²ng** | 48 â†’ 79 |
| **Má»¥c Ä‘Ã­ch** | Nháº­n request tá»« Frontend, lÆ°u file, trigger Celery |

**Input:**
- `face_image: UploadFile` - áº¢nh khuÃ´n máº·t
- `hair_image: UploadFile` - áº¢nh tÃ³c máº«u
- `description: str` - Prompt mÃ´ táº£
- `use_refiner: bool` - Báº­t/táº¯t Refiner

**Logic:**
```python
# DÃ²ng 60-61: Táº¡o tÃªn file random
face_filename = f"{uuid.uuid4()}_face.{ext}"
hair_filename = f"{uuid.uuid4()}_hair.{ext}"

# DÃ²ng 66-70: LÆ°u file vÃ o uploads/
with open(face_path, "wb") as f:
    shutil.copyfileobj(face_image.file, f)

# DÃ²ng 73: Trigger Celery Task
task = process_hair_transfer.delay(str(face_path), str(hair_path), description, use_refiner)
```

**Output:** `{"task_id": "abc123...", "status": "QUEUED"}`

---

### **2. `get_services()` - Lazy Load AI Models**

| File | `backend/app/tasks.py` |
|:---|:---|
| **DÃ²ng** | 29 â†’ 50 |
| **Má»¥c Ä‘Ã­ch** | Load models láº§n Ä‘áº§u tiÃªn, cache cho cÃ¡c task sau |

**Logic:**
```python
# DÃ²ng 36-41: Load 3 services
_SERVICES["face"] = FaceInfoService()      # InsightFace
_SERVICES["mask"] = SegmentationService()  # BiSeNet
_SERVICES["diffusion"] = HairDiffusionService()  # SDXL
```

---

### **3. `FaceInfoService.__init__()` - Khá»Ÿi táº¡o InsightFace**

| File | `backend/app/services/face.py` |
|:---|:---|
| **DÃ²ng** | 7 â†’ 20 |
| **Model** | InsightFace `antelopev2` |

**Logic:**
```python
# DÃ²ng 15-19: Khá»Ÿi táº¡o FaceAnalysis
self.app = FaceAnalysis(
    name='antelopev2',
    root=model_paths.INSIGHTFACE_ROOT,
    providers=['CUDAExecutionProvider', 'CPUExecutionProvider']
)
self.app.prepare(ctx_id=0, det_size=(640, 640))
```

---

### **4. `SegmentationService.__init__()` - Khá»Ÿi táº¡o BiSeNet**

| File | `backend/app/services/mask.py` |
|:---|:---|
| **DÃ²ng** | 56 â†’ 68 |
| **Model** | BiSeNet (19 classes) |

**Logic:**
```python
# DÃ²ng 60-63: Load BiSeNet
self.net = BiSeNet(n_classes=19)
self.net.load_state_dict(torch.load(model_paths.BISENET_CHECKPOINT))
self.net.to(self.device).eval()
```

---

### **5. `HairDiffusionService.__init__()` - Khá»Ÿi táº¡o SDXL**

| File | `backend/app/services/diffusion.py` |
|:---|:---|
| **DÃ²ng** | 20 â†’ 44 |

**Logic:**
```python
# DÃ²ng 29-30: Load SDXL pipeline
if self.use_sdxl:
    self._load_sdxl_pipeline()  # â†’ Gá»i hÃ m 6
```

---

### **6. `_load_sdxl_pipeline()` - Load SDXL + ControlNet + IP-Adapter**

| File | `backend/app/services/diffusion.py` |
|:---|:---|
| **DÃ²ng** | 112 â†’ 182 |

**Logic:**
```python
# DÃ²ng 117-121: Load ControlNet Depth
controlnet = ControlNetModel.from_pretrained(model_paths.CONTROLNET_DEPTH)

# DÃ²ng 135-140: Load SDXL Inpaint Pipeline
self.pipe = StableDiffusionXLControlNetInpaintPipeline.from_pretrained(
    model_paths.SDXL_BASE,
    controlnet=controlnet
)

# DÃ²ng 170-175: Load IP-Adapter
self.pipe.load_ip_adapter(
    model_paths.IP_ADAPTER_PLUS_HAIR,
    weight_name="ip-adapter-plus_sdxl_vit-h.bin"
)

# DÃ²ng 181: Chuyá»ƒn sang GPU
self.pipe.to(self.device, self.dtype)
```

---

### **7. `process_hair_transfer()` - Celery Task ChÃ­nh**

| File | `backend/app/tasks.py` |
|:---|:---|
| **DÃ²ng** | 52 â†’ 134 |
| **Má»¥c Ä‘Ã­ch** | Äiá»u phá»‘i toÃ n bá»™ quy trÃ¬nh AI |

**Logic:**
```python
# DÃ²ng 64-66: Load images
user_cv2 = cv2.imread(user_img_path)
user_pil = Image.fromarray(cv2.cvtColor(user_cv2, cv2.COLOR_BGR2RGB))
hair_pil = Image.open(hair_img_path).convert("RGB")

# DÃ²ng 80: Face Analysis
face_info = face_service.analyze(user_cv2)  # â†’ Gá»i hÃ m 8

# DÃ²ng 91: Create Hair Mask
hair_mask = mask_service.get_mask(user_pil, target_class=17)  # â†’ Gá»i hÃ m 9

# DÃ²ng 106-109: Depth Estimation
depth_estimator = pipeline("depth-estimation", model="Intel/dpt-large")
depth_map = depth_estimator(user_pil)['depth']

# DÃ²ng 113-120: Generate Image
result_image = diffusion_service.generate(
    base_image=user_pil,
    mask_image=hair_mask,
    control_image=depth_map,
    ref_hair_image=hair_pil,
    prompt=prompt
)  # â†’ Gá»i hÃ m 10

# DÃ²ng 123-125: Save output
filename = f"result_{self.request.id}.png"
result_image.save(os.path.join(OUTPUT_DIR, filename))
```

---

### **8. `FaceInfoService.analyze()` - Detect Face**

| File | `backend/app/services/face.py` |
|:---|:---|
| **DÃ²ng** | 22 â†’ 37 |

**Logic:**
```python
# DÃ²ng 27: Detect all faces
faces = self.app.get(image_cv2)

# DÃ²ng 32-36: Láº¥y máº·t lá»›n nháº¥t
faces = sorted(faces, key=lambda x: (x.bbox[2]-x.bbox[0]) * (x.bbox[3]-x.bbox[1]), reverse=True)
return faces[0]
```

**Output:** `face_info` vá»›i `.embedding`, `.kps`, `.bbox`

---

### **9. `SegmentationService.get_mask()` - Táº¡o Hair Mask**

| File | `backend/app/services/mask.py` |
|:---|:---|
| **DÃ²ng** | 70 â†’ 98 |

**Logic:**
```python
# DÃ²ng 77-79: Resize vÃ  transform
img_resized = image_pil.resize((512, 512))
img_tensor = self.to_tensor(img_resized).unsqueeze(0).to(self.device)

# DÃ²ng 81-83: BiSeNet inference
with torch.no_grad():
    out = self.net(img_tensor)[0]
    parsing = out.squeeze(0).cpu().numpy().argmax(0)

# DÃ²ng 87-88: Táº¡o binary mask (class 17 = hair)
mask = np.zeros_like(parsing).astype(np.uint8)
mask[parsing == 17] = 255

# DÃ²ng 94-95: Dilate mask
kernel = np.ones((5,5), np.uint8)
mask_dilated = cv2.dilate(mask, kernel, iterations=2)
```

**Output:** `PIL.Image` - Binary mask (0/255)

---

### **10. `HairDiffusionService.generate()` - Sinh áº¢nh AI**

| File | `backend/app/services/diffusion.py` |
|:---|:---|
| **DÃ²ng** | 214 â†’ 349 |

**Logic:**
```python
# DÃ²ng 232-236: Resize táº¥t cáº£ vá» 1024x1024
image = base_image.resize((1024, 1024))
mask = mask_image.resize((1024, 1024))
control = control_image.resize((1024, 1024))
ref_hair = ref_hair_image.resize((1024, 1024))

# DÃ²ng 243-244: Set IP-Adapter scale
self.pipe.set_ip_adapter_scale(0.6)

# DÃ²ng 272-290: Chuáº©n bá»‹ arguments
input_args = {
    "prompt": prompt,
    "image": image,
    "mask_image": mask,
    "control_image": control,
    "ip_adapter_image": ref_hair,
    "num_inference_steps": 30,
    "guidance_scale": 7.5,
    "controlnet_conditioning_scale": 0.5,
    "strength": 0.99
}

# DÃ²ng 296: Run inference
result = self.pipe(**input_args).images[0]

# (Optional) DÃ²ng 304-316: Run Refiner náº¿u use_refiner=True
if use_refiner and self.refiner:
    result = self.refiner(image=result, denoising_start=0.8).images[0]
```

**Output:** `PIL.Image` - áº¢nh káº¿t quáº£ 1024x1024

---

## ðŸ”„ Sequence Diagram

```mermaid
sequenceDiagram
    participant User
    participant API as main.py
    participant Task as tasks.py
    participant Face as face.py
    participant Mask as mask.py
    participant Depth as transformers
    participant Diff as diffusion.py
    
    User->>API: POST /generate (face_image, hair_image)
    API->>API: LÆ°u file vÃ o uploads/
    API->>Task: process_hair_transfer.delay()
    API-->>User: {task_id}
    
    Task->>Task: get_services() - Load AI models
    Task->>Task: cv2.imread(), Image.open()
    
    Task->>Face: analyze(user_cv2)
    Face-->>Task: face_info
    
    Task->>Mask: get_mask(user_pil, 17)
    Mask-->>Task: hair_mask
    
    Task->>Depth: depth_estimator(user_pil)
    Depth-->>Task: depth_map
    
    Task->>Diff: generate(image, mask, depth, ref_hair)
    Diff-->>Task: result_image
    
    Task->>Task: result_image.save()
    User->>API: GET /status/{task_id}
    API-->>User: {url: "/static/output/result_xxx.png"}
```

---

## âš ï¸ Ghi ChÃº

> **Model Loading:** Models Ä‘Æ°á»£c lazy load láº§n Ä‘áº§u trong worker process, cache cho cÃ¡c task sau.

> **GPU Memory:** SDXL + ControlNet + IP-Adapter cáº§n ~10GB VRAM. Táº¯t Refiner náº¿u thiáº¿u memory.

> **Hair Class:** BiSeNet class 17 = Hair trong CelebAMask-HQ dataset.
