# üîÑ TryHairStyle - Lu·ªìng Th·ª±c Thi Chi Ti·∫øt

---

## üìä S∆° ƒê·ªì T·ªïng Quan

```
[User Upload] ‚Üí [API Endpoint] ‚Üí [Celery Task] ‚Üí [AI Pipeline] ‚Üí [Output Image]
```

---

# üü¢ PHASE 1: FRONTEND ‚Üí API

## B∆∞·ªõc 1.1: User Upload ·∫¢nh
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `frontend/src/components/HairSwapper.jsx` |
| **H√†m** | `handleGenerate()` |
| **D√≤ng** | 82-116 |

**Th·ª±c hi·ªán:**
```javascript
// D√≤ng 92-96: T·∫°o FormData ch·ª©a 2 ·∫£nh
const formData = new FormData();
formData.append('face_image', targetFile);    // ·∫¢nh khu√¥n m·∫∑t
formData.append('hair_image', referenceFile); // ·∫¢nh t√≥c m·∫´u
formData.append('description', prompt);        // Prompt m√¥ t·∫£
formData.append('use_refiner', useRefiner);    // B·∫≠t/t·∫Øt refiner
```

---

## B∆∞·ªõc 1.2: API Nh·∫≠n Request
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/main.py` |
| **H√†m** | `generate_hair()` |
| **D√≤ng** | 48-79 |
| **Endpoint** | `POST /generate` |

**Th·ª±c hi·ªán:**

### 1.2.1: L∆∞u file v√†o th∆∞ m·ª•c uploads
```python
# D√≤ng 60-61: T·∫°o t√™n file ng·∫´u nhi√™n
face_filename = f"{uuid.uuid4()}_face.{ext}"
hair_filename = f"{uuid.uuid4()}_hair.{ext}"

# D√≤ng 63-64: X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n l∆∞u
face_path = UPLOAD_DIR / face_filename
hair_path = UPLOAD_DIR / hair_filename

# D√≤ng 66-70: Ghi file v√†o disk
with open(face_path, "wb") as f:
    shutil.copyfileobj(face_image.file, f)
with open(hair_path, "wb") as f:
    shutil.copyfileobj(hair_image.file, f)
```

### 1.2.2: Trigger Celery Task
```python
# D√≤ng 73: G·ªçi Celery task b·∫•t ƒë·ªìng b·ªô
task = process_hair_transfer.delay(
    str(face_path),   # ƒê∆∞·ªùng d·∫´n ·∫£nh m·∫∑t
    str(hair_path),   # ƒê∆∞·ªùng d·∫´n ·∫£nh t√≥c
    description,      # Prompt
    use_refiner       # C√≥ d√πng refiner kh√¥ng
)
```

### 1.2.3: Tr·∫£ v·ªÅ Task ID
```python
# D√≤ng 75-79: Response cho Frontend
return {
    "task_id": task.id,        # ID ƒë·ªÉ polling
    "status": "QUEUED",
    "message": "Task started successfully"
}
```

---

# üü° PHASE 2: CELERY WORKER KH·ªûI T·∫†O

## B∆∞·ªõc 2.1: Load AI Services (Lazy Loading)
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/tasks.py` |
| **H√†m** | `get_services()` |
| **D√≤ng** | 29-50 |

**Th·ª±c hi·ªán:**

### 2.1.1: Kh·ªüi t·∫°o FaceInfoService
```python
# File: backend/app/services/face.py
# H√†m: FaceInfoService.__init__()
# D√≤ng: 7-20

self.app = FaceAnalysis(
    name='antelopev2',                    # Model InsightFace
    root=model_paths.INSIGHTFACE_ROOT,    # Th∆∞ m·ª•c ch·ª©a model
    providers=['CUDAExecutionProvider']   # ∆Øu ti√™n GPU
)
self.app.prepare(ctx_id=0, det_size=(640, 640))  # Chu·∫©n b·ªã detect
```

### 2.1.2: Kh·ªüi t·∫°o SegmentationService
```python
# File: backend/app/services/mask.py
# H√†m: SegmentationService.__init__()
# D√≤ng: 56-68

from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation
self.processor = SegformerImageProcessor.from_pretrained(model_paths.SEGFORMER_LOCAL_PATH)
self.model = SegformerForSemanticSegmentation.from_pretrained(model_paths.SEGFORMER_LOCAL_PATH)
self.model.to(self.device).eval()
```

### 2.1.3: Kh·ªüi t·∫°o HairDiffusionService
```python
# File: backend/app/services/diffusion.py
# H√†m: HairDiffusionService.__init__()
# D√≤ng: 20-44

if self.use_sdxl:
    self._load_sdxl_pipeline()  # Load SDXL + ControlNet + IP-Adapter
```

### 2.1.4: Load SDXL Pipeline chi ti·∫øt
```python
# File: backend/app/services/diffusion.py
# H√†m: _load_sdxl_pipeline()
# D√≤ng: 112-182

# a) Load ControlNet Depth (D√≤ng 117-121)
controlnet = ControlNetModel.from_pretrained(
    model_paths.CONTROLNET_DEPTH,
    torch_dtype=torch.float16
)

# b) Load SDXL Inpaint Pipeline (D√≤ng 135-140)
self.pipe = StableDiffusionXLControlNetInpaintPipeline.from_pretrained(
    model_paths.SDXL_BASE,
    controlnet=controlnet,
    torch_dtype=torch.float16
)

# c) Load IP-Adapter (D√≤ng 170-175)
self.pipe.load_ip_adapter(
    model_paths.IP_ADAPTER_PLUS_HAIR,
    weight_name="ip-adapter-plus_sdxl_vit-h.bin"
)

# d) Chuy·ªÉn sang GPU (D√≤ng 181)
self.pipe.to(self.device, self.dtype)
```

---

# üîµ PHASE 3: X·ª¨ L√ù AI PIPELINE

## B∆∞·ªõc 3.1: Load ·∫¢nh ƒê·∫ßu V√†o
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/tasks.py` |
| **H√†m** | `process_hair_transfer()` |
| **D√≤ng** | 64-72 |

```python
# D√≤ng 64-66: Load ·∫£nh user (OpenCV + PIL)
user_cv2 = cv2.imread(user_img_path)
user_cv2 = cv2.cvtColor(user_cv2, cv2.COLOR_BGR2RGB)
user_pil = Image.fromarray(user_cv2)

# D√≤ng 70-72: Load ·∫£nh t√≥c m·∫´u
hair_pil = Image.open(hair_img_path).convert("RGB")
```

---

## B∆∞·ªõc 3.2: Ph√¢n T√≠ch Khu√¥n M·∫∑t (Face Analysis)
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/services/face.py` |
| **H√†m** | `FaceInfoService.analyze()` |
| **D√≤ng** | 22-37 |

**Th·ª±c hi·ªán:**

### 3.2.1: Detect t·∫•t c·∫£ khu√¥n m·∫∑t
```python
# D√≤ng 27: S·ª≠ d·ª•ng InsightFace detect
faces = self.app.get(image_cv2)
```

### 3.2.2: X·ª≠ l√Ω Profile Face (G√≥c nghi√™ng > 45¬∞)
```python
# Ki·ªÉm tra g√≥c Yaw t·ª´ Pose
if abs(yaw) > 45:
    # S·ª≠ d·ª•ng 3DDFA_V2 ƒë·ªÉ d·ª±ng 3D Pose & Landmarks
    # Th·ª±c hi·ªán Roll Correction (Xoay th·∫≥ng ƒë·∫ßu)
    # Align & Crop 112x112
    # Tr√≠ch xu·∫•t Embedding b·∫±ng AdaFace
else:
    # S·ª≠ d·ª•ng InsightFace/AdaFace 2D alignment th√¥ng th∆∞·ªùng
```

### 3.2.3: Ki·ªÉm tra v√† xoay ·∫£nh n·∫øu c·∫ßn
```python
# D√≤ng 29-31: N·∫øu kh√¥ng t√¨m th·∫•y m·∫∑t, th·ª≠ xoay 90¬∞
if len(faces) == 0:
    rotated = cv2.rotate(image_cv2, cv2.ROTATE_90_CLOCKWISE)
    faces = self.app.get(rotated)
```

### 3.2.4: Ch·ªçn khu√¥n m·∫∑t l·ªõn nh·∫•t
```python
# D√≤ng 32-36: Sort theo di·ªán t√≠ch bbox
faces = sorted(
    faces, 
    key=lambda x: (x.bbox[2]-x.bbox[0]) * (x.bbox[3]-x.bbox[1]), 
    reverse=True
)
return faces[0]  # Tr·∫£ v·ªÅ m·∫∑t l·ªõn nh·∫•t
```

**Output:** Object `face_info` ch·ª©a:
- `.embedding` - Vector ƒë·∫∑c tr∆∞ng khu√¥n m·∫∑t (512D)
- `.kps` - 5 keypoints (m·∫Øt, m≈©i, mi·ªáng)
- `.bbox` - Bounding box [x1, y1, x2, y2]

---

## B∆∞·ªõc 3.3: T·∫°o Hair Mask (Segmentation)
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/services/mask.py` |
| **H√†m** | `SegmentationService.get_mask()` |
| **D√≤ng** | 70-98 |

**Th·ª±c hi·ªán:**

### 3.3.1: Resize ·∫£nh v·ªÅ 512x512
```python
# D√≤ng 74-75: L∆∞u k√≠ch th∆∞·ªõc g·ªëc
w, h = image_pil.size

# D√≤ng 77: Resize cho SegFormer
img_resized = image_pil.resize((512, 512), Image.BILINEAR)
```

### 3.3.2: Transform sang Tensor
```python
# D√≤ng 79: Chuy·ªÉn sang tensor GPU
img_tensor = self.to_tensor(img_resized).unsqueeze(0).to(self.device)
```

### 3.3.3: Ch·∫°y SegFormer inference
```python
# D√≤ng 81-83: Forward pass
with torch.no_grad():
    out = self.net(img_tensor)[0]
    parsing = out.squeeze(0).cpu().numpy().argmax(0)
```

### 3.3.4: T·∫°o binary mask cho class "hair" (17)
```python
# D√≤ng 87-88: Class 17 = Hair trong CelebAMask-HQ
mask = np.zeros_like(parsing).astype(np.uint8)
mask[parsing == 17] = 255  # V√πng t√≥c = tr·∫Øng (255)
```

### 3.3.5: Resize v·ªÅ k√≠ch th∆∞·ªõc g·ªëc
```python
# D√≤ng 91: Resize mask v·ªÅ k√≠ch th∆∞·ªõc ·∫£nh g·ªëc
mask_cv2 = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)
```

### 3.3.6: Dilate mask (m·ªü r·ªông v√πng)
```python
# D√≤ng 94-95: M·ªü r·ªông mask ƒë·ªÉ inpaint t·ªët h∆°n
kernel = np.ones((5, 5), np.uint8)
mask_dilated = cv2.dilate(mask_cv2, kernel, iterations=2)
```

**Output:** `PIL.Image` - Binary mask (0 = kh√¥ng t√≥c, 255 = v√πng t√≥c)

---

## B∆∞·ªõc 3.4: ∆Ø·ªõc T√≠nh Depth Map
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/tasks.py` |
| **D√≤ng** | 106-109 |
| **Model** | `Intel/dpt-large` (HuggingFace) |

```python
# D√≤ng 106-107: Load depth estimator
from transformers import pipeline
depth_estimator = pipeline("depth-estimation", model="Intel/dpt-large")

# D√≤ng 109: Ch·∫°y inference
depth_result = depth_estimator(user_pil)
depth_map = depth_result['depth']  # PIL Image grayscale
```

**Output:** `PIL.Image` - Grayscale depth map (g·∫ßn = s√°ng, xa = t·ªëi)

---

## B∆∞·ªõc 3.5: Sinh ·∫¢nh AI (SDXL Inpainting)
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/services/diffusion.py` |
| **H√†m** | `HairDiffusionService.generate()` |
| **D√≤ng** | 214-349 |

**Th·ª±c hi·ªán:**

### 3.5.1: Resize t·∫•t c·∫£ input v·ªÅ 1024x1024
```python
# D√≤ng 232-236: SDXL y√™u c·∫ßu 1024x1024
image = base_image.resize((1024, 1024), Image.LANCZOS)
mask = mask_image.resize((1024, 1024), Image.NEAREST)
control = control_image.resize((1024, 1024), Image.LANCZOS)
ref_hair = ref_hair_image.resize((1024, 1024), Image.LANCZOS)
```

### 3.5.2: Set IP-Adapter scale
```python
# D√≤ng 243-244: ƒê·ªô m·∫°nh c·ªßa style transfer
self.pipe.set_ip_adapter_scale(0.6)  # 0.6 = v·ª´a ph·∫£i
```

### 3.5.3: Chu·∫©n b·ªã Generator cho reproducibility
```python
# D√≤ng 255-256: Random seed
generator = torch.Generator(device=self.device)
generator.manual_seed(42)  # Seed c·ªë ƒë·ªãnh ƒë·ªÉ k·∫øt qu·∫£ ·ªïn ƒë·ªãnh
```

### 3.5.4: Chu·∫©n b·ªã arguments cho pipeline
```python
# D√≤ng 272-290: T·∫•t c·∫£ tham s·ªë
input_args = {
    "prompt": prompt,                          # "high quality hair..."
    "negative_prompt": negative_prompt,        # "blurry, bad quality..."
    "image": image,                            # ·∫¢nh g·ªëc 1024x1024
    "mask_image": mask,                        # Hair mask
    "control_image": control,                  # Depth map
    "ip_adapter_image": ref_hair,              # ·∫¢nh t√≥c m·∫´u
    "num_inference_steps": 30,                 # S·ªë b∆∞·ªõc diffusion
    "guidance_scale": 7.5,                     # CFG scale
    "controlnet_conditioning_scale": 0.5,      # ƒê·ªô m·∫°nh ControlNet
    "strength": 0.99,                          # Inpaint strength
    "generator": generator
}
```

### 3.5.5: Ch·∫°y SDXL Pipeline
```python
# D√≤ng 296: Forward pass ch√≠nh
result = self.pipe(**input_args).images[0]
```

### 3.5.6: (Optional) Ch·∫°y Refiner
```python
# D√≤ng 304-316: N·∫øu use_refiner=True
if use_refiner and self.refiner:
    result = self.refiner(
        prompt=prompt,
        image=result,
        num_inference_steps=20,
        denoising_start=0.8,       # Ch·ªâ refine 20% cu·ªëi
        generator=generator
    ).images[0]
```

**Output:** `PIL.Image` - ·∫¢nh k·∫øt qu·∫£ 1024x1024

---

# üü£ PHASE 4: L∆ØU K·∫æT QU·∫¢ V√Ä TR·∫¢ V·ªÄ

## B∆∞·ªõc 4.1: L∆∞u ·∫¢nh Output
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/tasks.py` |
| **D√≤ng** | 123-125 |

```python
# D√≤ng 123: T·∫°o t√™n file v·ªõi task ID
filename = f"result_{self.request.id}.png"

# D√≤ng 124: ƒê∆∞·ªùng d·∫´n ƒë·∫ßy ƒë·ªß
output_path = os.path.join(OUTPUT_DIR, filename)

# D√≤ng 125: L∆∞u file
result_image.save(output_path)
```

---

## B∆∞·ªõc 4.2: Tr·∫£ V·ªÅ K·∫øt Qu·∫£
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/tasks.py` |
| **D√≤ng** | 127-134 |

```python
# D√≤ng 127-134: Return dict cho Celery
return {
    "status": "SUCCESS",
    "url": f"/static/output/{filename}",  # URL ƒë·ªÉ Frontend download
    "filename": filename
}
```

---

## B∆∞·ªõc 4.3: Frontend Polling Status
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `frontend/src/components/HairSwapper.jsx` |
| **H√†m** | `useEffect` (polling) |
| **D√≤ng** | 17-48 |

```javascript
// D√≤ng 22-42: Poll m·ªói 2 gi√¢y
intervalId = setInterval(async () => {
    const response = await fetch(`/status/${taskId}`);
    const data = await response.json();
    
    if (data.status === 'SUCCESS') {
        setResultUrl(data.result_url);  // Hi·ªÉn th·ªã ·∫£nh
        setIsLoading(false);
    }
}, 2000);
```

---

## B∆∞·ªõc 4.4: API Tr·∫£ Status
| Chi ti·∫øt | Gi√° tr·ªã |
|:---|:---|
| **File** | `backend/app/main.py` |
| **H√†m** | `get_task_status()` |
| **D√≤ng** | 107-135 |

```python
# D√≤ng 112: L·∫•y k·∫øt qu·∫£ t·ª´ Celery
task_result = AsyncResult(task_id, app=celery_app)

# D√≤ng 119-124: N·∫øu SUCCESS, tr·∫£ v·ªÅ URL
if task_result.status == 'SUCCESS':
    result_data = task_result.result
    response["result_url"] = result_data.get("url")
```

---

# üìã B·∫¢NG T√ìM T·∫ÆT

| Phase | B∆∞·ªõc | File | H√†m | M√¥ t·∫£ |
|:---:|:---:|:---|:---|:---|
| 1 | 1.1 | `HairSwapper.jsx` | `handleGenerate()` | User upload ·∫£nh |
| 1 | 1.2 | `main.py` | `generate_hair()` | API nh·∫≠n + l∆∞u file |
| 2 | 2.1 | `tasks.py` | `get_services()` | Load AI models |
| 2 | 2.1.1 | `face.py` | `FaceInfoService.__init__()` | Load InsightFace |
| 2 | 2.1.2 | `mask.py` | `SegmentationService.__init__()` | Load SegFormer |
| 2 | 2.1.3 | `diffusion.py` | `_load_sdxl_pipeline()` | Load SDXL |
| 3 | 3.1 | `tasks.py` | `process_hair_transfer()` | Load ·∫£nh |
| 3 | 3.2 | `face.py` | `analyze()` | Detect face |
| 3 | 3.3 | `mask.py` | `get_mask()` | T·∫°o hair mask |
| 3 | 3.4 | `tasks.py` | `depth_estimator()` | T·∫°o depth map |
| 3 | 3.5 | `diffusion.py` | `generate()` | Sinh ·∫£nh SDXL |
| 4 | 4.1 | `tasks.py` | `process_hair_transfer()` | L∆∞u output |
| 4 | 4.2 | `main.py` | `get_task_status()` | Tr·∫£ v·ªÅ URL |
